#!/usr/bin/env python

import sys
import argparse
import collections
import zhtext

class Output:
    def __init__(self, fileinput):
        self.text_parts = zhtext.split_hanzi_nonhanzi(fileinput.read().decode('utf-8'))
        self.dictionary = zhtext.read_dictionary()
        self.frequencies = zhtext.read_frequencies(self.dictionary, self.text_parts)
        self.segmented_text = zhtext.segment(self.dictionary, self.frequencies, self.text_parts)
        self.words = zhtext.get_words(self.segmented_text)

def segment(args):
    output = Output(args.file)
    for i, part in enumerate(output.segmented_text):
        if i % 2 == 0:
            sys.stdout.write(part.encode('utf-8'))
        else:
            sys.stdout.write(' '.join(part).encode('utf-8'))

def word_counts(args):
    output = Output(args.file)

    counter = collections.Counter()
    for word in output.words:
        counter[word] += 1

    for word, count in counter.most_common():
        sys.stdout.write(("%s %d\n" % (word, count)).encode('utf-8'))

parser = argparse.ArgumentParser()
subparsers = parser.add_subparsers()

parser_segment = subparsers.add_parser('segment', help='Segments the given chinese text into words.')
parser_segment.add_argument('file', metavar='FILE', type=argparse.FileType('r'), help='text file to segment')
parser_segment.set_defaults(func=segment)

parser_counts = subparsers.add_parser('counts', help='Print the distinct words occuring in a chinese text along with the count of each word.')
parser_counts.add_argument('file', metavar='FILE', type=argparse.FileType('r'), help='text file to process')
parser_counts.set_defaults(func=word_counts)

args = parser.parse_args()
args.func(args)
